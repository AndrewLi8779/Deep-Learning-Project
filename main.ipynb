{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as metrics\n",
    "import numpy as np\n",
    "import audio_preprocessor\n",
    "\n",
    "saved_var_path = \"D:/dlp/\"\n",
    "data_path = \"data/maestro-v3.0.0/\"\n",
    "meta = audio_preprocessor.load_metadata(data_path + 'maestro-v3.0.0.json')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def data_idx():\n",
    "    train_idx, test_idx, val_idx = [], [], []\n",
    "    for i in range(len(meta['duration'])):\n",
    "        if meta['split'][str(i)] == 'train':\n",
    "            train_idx.append(i)\n",
    "        if meta['split'][str(i)] == 'test':\n",
    "            test_idx.append(i)\n",
    "        if meta['split'][str(i)] == 'val':\n",
    "            val_idx.append(i)\n",
    "    return np.array(train_idx), np.array(test_idx), np.array(val_idx)\n",
    "\n",
    "train_idx, test_idx, val_idx = data_idx()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[0.0000e+00, 3.1589e-02, 1.1039e-02,  ..., 4.5782e-06,\n           2.2328e-06, 2.4014e-06],\n          [0.0000e+00, 3.8172e-02, 1.3339e-02,  ..., 3.9699e-06,\n           1.7287e-06, 2.6934e-06],\n          [0.0000e+00, 4.3522e-02, 1.5209e-02,  ..., 3.6432e-06,\n           1.6371e-06, 2.9135e-06],\n          ...,\n          [0.0000e+00, 1.2246e-01, 4.2792e-02,  ..., 7.4013e-06,\n           7.5451e-06, 6.8976e-06],\n          [0.0000e+00, 1.3193e-01, 4.6101e-02,  ..., 6.3619e-06,\n           7.5539e-06, 7.8163e-06],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]],\n \n         [[0.0000e+00, 1.4271e-01, 4.9868e-02,  ..., 5.1201e-06,\n           7.3039e-06, 8.1336e-06],\n          [0.0000e+00, 1.5432e-01, 5.3926e-02,  ..., 4.0330e-06,\n           6.7496e-06, 7.6835e-06],\n          [0.0000e+00, 1.6617e-01, 5.8069e-02,  ..., 3.3594e-06,\n           5.9003e-06, 6.5843e-06],\n          ...,\n          [0.0000e+00, 1.0306e-02, 3.6015e-03,  ..., 5.8190e-06,\n           3.3819e-06, 4.0760e-06],\n          [0.0000e+00, 1.9033e-02, 6.6509e-03,  ..., 5.5577e-06,\n           3.2173e-06, 3.8199e-06],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]]], device='cuda:0'),\n tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 1., 0.],\n          [0., 0., 0.,  ..., 0., 1., 0.],\n          [0., 0., 0.,  ..., 0., 1., 0.]],\n \n         [[0., 0., 0.,  ..., 0., 0., 1.],\n          [0., 0., 0.,  ..., 0., 1., 0.],\n          [0., 0., 0.,  ..., 0., 1., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 1., 0.],\n          [0., 0., 0.,  ..., 0., 1., 0.],\n          [0., 0., 0.,  ..., 0., 1., 0.]]], device='cuda:0'))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_train_batch(batch_size=2):\n",
    "    idx = np.random.choice(train_idx)\n",
    "    X = np.load(saved_var_path + 'train/spec/train_spec_' + str(idx) + '.npy')\n",
    "    start = np.random.randint(0, X.shape[0] - batch_size)\n",
    "    X = X[start:start + batch_size]\n",
    "    y = np.load(saved_var_path + 'train/midi/train_midi_' + str(idx) + '.npy')\n",
    "    y = y[start:start + batch_size]\n",
    "    b = torch.nn.functional.one_hot(torch.tensor(y[0]).to(torch.int64), num_classes=512)\n",
    "    for i in range(batch_size - 1):\n",
    "        b = torch.stack((b, torch.nn.functional.one_hot(torch.tensor(y[i + 1]).to(torch.int64), num_classes=512)))\n",
    "\n",
    "    return torch.tensor(X).to(device), b.to(torch.float32).to(device)\n",
    "\n",
    "sample_train_batch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2048, 512])\n"
     ]
    }
   ],
   "source": [
    "model = nn.Transformer(nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=1024, batch_first=True).to(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "src = torch.rand((2, 128, 512)).to(device)\n",
    "tgt = torch.rand((2, 2048, 512)).to(device)\n",
    "out = model(src, tgt)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "del src\n",
    "del tgt\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_function = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train(model, loss_function, optimizer):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    for i in range(200000):\n",
    "        X, y = sample_train_batch()\n",
    "        # zero out the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # do forward pass with current batch of input\n",
    "        outs = model(X, y)\n",
    "        # get loss with model predictions and true labels\n",
    "        loss = loss_function(outs, y)\n",
    "        # update model parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 1000 == 0:\n",
    "            log = \"Training Step \" + str(i) + \": loss: \" + str(loss)\n",
    "            print(log)\n",
    "            torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, \"model\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step 0: loss: tensor(30.5020, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 1000: loss: tensor(30.4986, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 2000: loss: tensor(30.4991, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 3000: loss: tensor(30.4986, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 4000: loss: tensor(30.4984, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 5000: loss: tensor(30.4986, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 6000: loss: tensor(30.4988, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 7000: loss: tensor(30.4985, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 8000: loss: tensor(30.4984, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 9000: loss: tensor(30.4984, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 10000: loss: tensor(30.4984, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 11000: loss: tensor(30.4986, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 12000: loss: tensor(30.4983, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 13000: loss: tensor(30.4986, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Training Step 14000: loss: tensor(30.4984, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_function, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}